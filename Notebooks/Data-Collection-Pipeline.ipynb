{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480db4cf-c314-4428-93d4-7547fa7bc8ce",
   "metadata": {},
   "source": [
    "# Collecting Textual News Data from Twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3462a4af-0549-4065-931f-c0b38d8e5685",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91b13a-5abe-4462-b404-bfc0ccbfd0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36e209c-db8c-4996-b850-f63a35a83e28",
   "metadata": {},
   "source": [
    "## Setting Up Twitter API and Tokens from .env File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d6419-0938-40a8-a19f-503049d37f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d93073-d4b5-4d24-a44b-f78233ed5ee3",
   "metadata": {},
   "source": [
    "## Setting Up Twitter Screaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d0056-3217-437d-a946-d0fb35c74d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "userID = []\n",
    "tweetID = []\n",
    "tweet_url = []\n",
    "username = []\n",
    "next_page_token = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f71e00-0fae-4057-be29-5e158be242a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClient():\n",
    "    \n",
    "    client = tweepy.Client(bearer_token= os.getenv(\"BEARER_TOKEN\"),\n",
    "                           consumer_key=os.getenv(\"API_KEY\"), \n",
    "                           consumer_secret=os.getenv(\"API_KEY_SECRET\"), \n",
    "                           access_token=os.getenv(\"ACCESS_TOKEN\"),\n",
    "                           access_token_secret=os.getenv(\"ACCESS_TOKEN_SECRET\"))\n",
    "\n",
    "    return client\n",
    "\n",
    "\n",
    "def searchTweets(query, qty):\n",
    "    \n",
    "    client = getClient() # First Function is called right here.\n",
    "    client_call = client.search_all_tweets(query=query, max_results=qty, expansions='author_id') # API call to get the Data\n",
    "    \n",
    "    if not client_call.data is None and len(client_call.data) > 0: #Checking if there are results or not before looping...\n",
    "        for tweet in client_call.data:\n",
    "            tweets.append(tweet.text)        #Adding Tweets to the List created before           \n",
    "            tweetID.append(tweet.id)         #Adding Tweets IDs to the List created before\n",
    "            userID.append(tweet.author_id)   #Adding Users IDs to the List created before\n",
    "            tweet_url.append('https://twitter.com/{}/status/{}'.format(tweet.author_id, tweet.id))\n",
    "                          # ↑Adding Tweet URL to the List created before ↑\n",
    "    else:\n",
    "        return ['NO DATA WAS FOUND']\n",
    "    \n",
    "    # Using try and except to avoid getting erros in the script during the data collection\n",
    "    try:\n",
    "        next_page = client_call.meta['next_token']\n",
    "        next_page_token.append(next_page)\n",
    "    except KeyError:\n",
    "        print(\"NO NEXT TOKEN AVAILABLE, THIS MEANS YOU GOT ONLY ONE PAGE.... :( \")\n",
    "\n",
    "    df = pd.DataFrame({'Tweets': tweets, \"Tweet URL\": tweet_url, 'Tweet ID': tweetID, \"User ID\": userID})\n",
    "           \n",
    "    return df \n",
    "\n",
    "\n",
    "def search_tweets_next(query, qty, next_page_token, pagination):\n",
    "    \n",
    "    client = getClient() # First Function is called right here.\n",
    "\n",
    "     # ↓ API call to get the Data ↓\n",
    "    client_call_ = client.search_all_tweets(query=query, max_results=qty, expansions='author_id', next_token=next_page_token[pagination])\n",
    "   \n",
    "    if not client_call_.data is None and len(client_call_.data) > 0: #Checking if there are results or not before looping...\n",
    "        for tweet in client_call_.data:\n",
    "            tweets.append(tweet.text)        #Adding Tweets to the List created before\n",
    "            tweetID.append(tweet.id)         #Adding Tweets IDs to the List created before\n",
    "            userID.append(tweet.author_id)   #Adding Users IDs to the List created before\n",
    "            tweet_url.append('https://twitter.com/{}/status/{}'.format(tweet.author_id, tweet.id))\n",
    "                          # ↑Adding Tweet URL to the List created before ↑\n",
    "    else:\n",
    "        return ['NO DATA']\n",
    "    # Using try and except to avoid getting erros in the script during the data collection\n",
    "    try:\n",
    "        next_page = client_call_.meta['next_token']\n",
    "        next_page_token.append(next_page)\n",
    "    except KeyError:\n",
    "        print(\"NO NEXT TOKEN AVAILABLE, THIS MEANS YOU GOT UNTIL THIS PAGE:( .... :( \")\n",
    "    \n",
    "    df = pd.DataFrame({'Tweets': tweets, \"Tweet URL\": tweet_url, 'Tweet ID': tweetID, \"User ID\": userID})\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_user_by_id(userID):\n",
    "    \n",
    "    client = getClient()\n",
    "    client_call = client.get_user(id=userID)\n",
    "    user_id = client_call.data.username\n",
    "    \n",
    "    return user_id\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08be469-a464-4379-bb3a-d98c4283522a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calling Function to search for tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bcf583-2d69-4850-a4e7-02401e684079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Data Request\n",
    "NewsAccounts = ['factcheckdotorg', 'CNN', 'Forbes', 'BBCBreaking', 'BBC', \n",
    "                'nytimes', 'WSJ', 'washingtonpost', 'NewYorker', \n",
    "                'AP', 'Reuters', 'Bloomberg', 'ForeignAffairs', \n",
    "                'TheAtlantic', 'politico']\n",
    "\n",
    "FakeNewsAccounts = ['TheOnion']\n",
    "\n",
    "df = searchTweets('from:{} -is:retweet lang:en'.format(NewsAccounts[0]), 500)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc24ee49-6edc-4e95-bd32-69ae4bc679a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data requests adding pagination token (each request gets 500 tweets, every single execuion I have to change the token manually)\n",
    "pagination = 0\n",
    "df = search_tweets_next('from:{} -is:retweet lang:en'.format(NewsAccounts[0]), 500, next_page_token, pagination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf11ebb5-32f0-4798-8f9c-f9a2d56f43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Datasets/TrustedNews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608577c0-6564-44df-8f1d-6d3daa5330ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j2/64m37fcx0fx_w8wpmhz91lmh0000gn/T/ipykernel_97115/1396537375.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv('Datasets/FakeNews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9edeca-ee81-46d5-ba84-ef6e58e43eb2",
   "metadata": {},
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Fake-News-Pipeline",
   "language": "python",
   "name": "ml-fake-news-pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
